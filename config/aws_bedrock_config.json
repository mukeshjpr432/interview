{
  "bedrock_models": {
    "claude_3_sonnet": {
      "model_id": "anthropic.claude-3-sonnet-20240229-v1:0",
      "provider": "Anthropic",
      "description": "Fast, intelligent model - best for interview orchestration",
      "max_tokens": 2000,
      "temperature": 0.7,
      "use_case": "All agents (Interviewer, Evaluator, Coach)"
    },
    "claude_3_haiku": {
      "model_id": "anthropic.claude-3-haiku-20240307-v1:0",
      "provider": "Anthropic",
      "description": "Faster, more compact - for simple tasks",
      "max_tokens": 1024,
      "temperature": 0.5,
      "use_case": "Response classification, simple follow-ups"
    },
    "claude_3_opus": {
      "model_id": "anthropic.claude-3-opus-20240229-v1:0",
      "provider": "Anthropic",
      "description": "Most capable - for complex reasoning",
      "max_tokens": 2000,
      "temperature": 0.7,
      "use_case": "Coach Agent (detailed feedback generation)"
    },
    "llama_2_70b": {
      "model_id": "meta.llama2-70b-chat-v1:0",
      "provider": "Meta",
      "description": "Open-source, powerful model",
      "max_tokens": 2000,
      "temperature": 0.7,
      "use_case": "Alternative to Claude"
    },
    "mistral_7b": {
      "model_id": "mistral.mistral-7b-instruct-v0:2",
      "provider": "Mistral",
      "description": "Fast, lightweight model",
      "max_tokens": 2000,
      "temperature": 0.7,
      "use_case": "Quick responses, Q&A"
    }
  },
  "agent_configurations": {
    "interviewer_agent": {
      "model_id": "anthropic.claude-3-sonnet-20240229-v1:0",
      "temperature": 0.8,
      "max_tokens": 1500,
      "system_prompt": "src/agents/interviewer_agent_prompt.md",
      "role": "Conduct natural, adaptive interviews",
      "parameters": {
        "top_p": 0.9,
        "top_k": 50
      }
    },
    "evaluator_agent": {
      "model_id": "anthropic.claude-3-opus-20240229-v1:0",
      "temperature": 0.5,
      "max_tokens": 2000,
      "system_prompt": "src/agents/evaluator_agent_prompt.md",
      "role": "Score and evaluate interview responses",
      "parameters": {
        "top_p": 0.7,
        "top_k": 40
      }
    },
    "coach_agent": {
      "model_id": "anthropic.claude-3-opus-20240229-v1:0",
      "temperature": 0.7,
      "max_tokens": 2000,
      "system_prompt": "src/agents/coach_agent_prompt.md",
      "role": "Generate detailed coaching feedback",
      "parameters": {
        "top_p": 0.9,
        "top_k": 50
      }
    }
  },
  "aws_services": {
    "bedrock": {
      "region": "us-east-1",
      "service_name": "bedrock-runtime"
    },
    "transcribe": {
      "region": "us-east-1",
      "service_name": "transcribe",
      "language_code": "en-US"
    },
    "polly": {
      "region": "us-east-1",
      "service_name": "polly",
      "voice_ids": ["Joanna", "Matthew", "Salli", "Joey"]
    },
    "dynamodb": {
      "region": "us-east-1",
      "tables": [
        "interview_sessions",
        "evaluation_results",
        "interview_transcripts",
        "candidate_profiles"
      ]
    },
    "s3": {
      "region": "us-east-1",
      "bucket_name": "interview-coach-voice-storage",
      "paths": {
        "audio_uploads": "audio/",
        "transcripts": "transcripts/",
        "reports": "reports/"
      }
    },
    "lambda": {
      "region": "us-east-1",
      "functions": [
        "interview-orchestrator",
        "voice-handler",
        "report-generator"
      ]
    },
    "api_gateway": {
      "region": "us-east-1",
      "stage": "prod",
      "endpoints": {
        "start_interview": "POST /interview/start",
        "send_response": "POST /interview/{id}/response",
        "end_interview": "POST /interview/{id}/end",
        "get_report": "GET /interview/{id}/report"
      }
    }
  },
  "request_parameters": {
    "interview_question": {
      "max_length": 500,
      "min_length": 20,
      "timeout_seconds": 30
    },
    "candidate_response": {
      "max_length": 2000,
      "min_length": 10,
      "timeout_seconds": 60
    },
    "evaluation": {
      "timeout_seconds": 45,
      "retry_count": 2
    }
  },
  "error_handling": {
    "bedrock_timeout": {
      "timeout_ms": 30000,
      "retry_strategy": "exponential_backoff",
      "max_retries": 3
    },
    "dynamo_throttle": {
      "retry_strategy": "exponential_backoff",
      "max_retries": 5
    },
    "transcribe_failure": {
      "fallback": "manual_transcription_request",
      "timeout_ms": 60000
    }
  },
  "cost_optimization": {
    "model_selection": {
      "strategy": "Use Haiku for quick tasks, Sonnet for main interview, Opus for evaluation",
      "estimated_tokens_per_interview": 4000,
      "estimated_cost_per_interview": 0.12
    },
    "batch_processing": {
      "enabled": true,
      "batch_size": 10
    },
    "caching": {
      "enabled": true,
      "ttl_seconds": 3600
    }
  }
}
